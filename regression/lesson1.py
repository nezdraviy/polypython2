#Машинное обучение

#ML - решает следующую задачу
#Требуется подогнать набор точен данных под соответствующую
#функцию, которая улавливает важные сигналы и игнорирует помехи. Нужно обобщить функцию на новые данные

#Обучение с учителем (супервайзд)
#Обучение без учителя (ансупервайзд)

#ОсУ - моделирует отношение между признаками и метками. Служат для предсказания меток на основе обучающих данных маркированных. 
#После построения модели можно использовать её для присвоения меток новым ранее неизвестным данным

# - задача классификации (метки - дискретные)
# - задача регрессии (метки/результат: непрерывные величины)

#ОбУ - моедлирование без меток. Такие модели служат для выялвения структуры немаркированных данных.

# - задача кластеризации (выделение групп данных)
# - понижение размерности (поиск более сжатого представления данных)

# Существуют методы частичного обучения (семи-супрвайсед). Не все данные промаркированны.

# Методы обучения с подкреплением (реинфорсент). Система обучения улучшает свои характеристики на основе взаимодействия (обратной связи со средой). 
# При этом взаимодействии система получает сигналы, которые несут в себе информацию насколько хорошо/плохо система решила задачу.

import seaborn as sns
import pandas as pd
import numpy as np

iris = sns.load_dataset('iris')

print(iris.head())

print(iris.values.shape)

#Строки - отдельные объекты (образцы)
#Столбцы - признаки
#Матрица признаков размер (число образцов х число признаков)
#Целевой массив, массив меток, таргеты - одномерный массив 
#Зависимые и независимые переменные

#Процесс построения системы машинного обучения 

#1. Предварительная обработка
# - На вход поступают необработанные данные и метки
# - Выбор признаков, масштабирование признаков
# - Понижение размерности
# - Выборка образцов
# - На выход поступает набор данных: (обучающий набор и тестовый набор)

#2. Обучение 
# - Выбор модели
# - Перекрестная проверка
# - Метрики эффективности модели
# - Оптимизация гиперпараметров, параметры, которые получаются не из данных, а которые являются характеристиками модели

#3. Оценка и формирование финальной модели
#
#4. Прогназирование (использование модели)

import matplotlib.pyplot as plt

np.random.seed(1)

#Scikit - learn
#1. Выбираем класс модели
from sklearn.linear_model import LinearRegression
#2. Устанавиваем гиперпараметры модели
model = LinearRegression()
#3. Создаём матрицу признаков и целевой массив
x = 10 * np.random.rand(50)
y = 2 * x - 1 + np.random.randn(50)
X = x[:, np.newaxis]
#4. Обучение модели fit()
model.fit(X, y)
print(model.coef_[0])
print(model.intercept_)

x_pred = np.linspace(0, 10, 30)
y_pred = model.coef_[0] * x_pred + model.intercept_
plt.scatter(x, y)
plt.plot(x_pred, y_pred)
#5. Применить модель к новым данным

xfit = np.linspace(-10, 10, 5)
yfit = model.predict(xfit[:, np.newaxis])

plt.scatter(xfit, yfit)

plt.show()
# - predict() (с учителем)
# - transform() (без учителя)

#Обучение с учителем: Линейная регрессия

#Простая линейная регрессия 

# y = ax + b


